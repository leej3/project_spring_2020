{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Workbook\n",
    "### BIOF 309 Spring 2020 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ramita Karra <br>\n",
    "**Last edited:** 04-23-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and set up package files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new a directory and directory structure for the package (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile initialize.py\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "def create_package_dir(package_name='BIOF309_RDK'):\n",
    "    \"\"\" This function creates a new directory within the current directory using the passed input string \n",
    "    package_name. If a directory with the same name as package_name already exists, it deletes the old \n",
    "    directory.\"\"\"\n",
    "    \n",
    "    start_dir = Path.cwd()\n",
    "    print(f\"Starting in {start_dir}\")\n",
    "\n",
    "    if start_dir.name == package_name:\n",
    "        os.chdir(start_dir.parent)\n",
    "        package_dir = start_dir\n",
    "    else:\n",
    "        package_dir = start_dir / package_name\n",
    "    \n",
    "    if package_dir.exists():\n",
    "        print(\"Removing old directory...\")\n",
    "        shutil.rmtree(package_dir)\n",
    "\n",
    "    print(f\"Creating {package_dir}...\")\n",
    "    package_dir.mkdir()\n",
    "    print(f\"The current working directory is now {package_dir}\")\n",
    "    os.chdir(package_dir)\n",
    "    \n",
    "def create_package_str(package_name='EHT_RDK'):\n",
    "    \"\"\" This function creates a new package structure within the current directory. It creates a new directory\n",
    "    to house code, with the passed input string package_name, as well as blank files for 'init.py' within the \n",
    "    new directory, setup.py, License and Readme files.\"\"\"\n",
    "    \n",
    "    Path('tests').mkdir()\n",
    "    python_dir = Path(package_name)\n",
    "    python_dir.mkdir()\n",
    "    (python_dir / '__init__.py').touch()\n",
    "    Path('setup.py').touch()\n",
    "    Path('LICENSE').touch()\n",
    "    Path('README.md').touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import create_package_dir, create_package_str\n",
    "\n",
    "create_package_dir('BIOF309_RDK')\n",
    "create_package_str('EHT_RDK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metadata and installation details (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "# Metadata and installation details for the EHT_RDK package\n",
    "\n",
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"EHT_RDK\", \n",
    "    version=\"0.0.1\",\n",
    "    author=\"Ramita D. Karra\",\n",
    "    author_email=\"ramita.karra@nih.gov\",\n",
    "    description=\"A package for processing Expansion Hunter Targeted (EHT) repeat data\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/pypa/packaging_demo\",\n",
    "    packages=setuptools.find_packages(),\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile README.md\n",
    "\n",
    "# EHT_RDK\n",
    "## Package Description\n",
    "<br>\n",
    "This aim of this package is to process raw tab-delimited output returned from the ExpansionHunter-Targeted \n",
    "software tool, used for making sequence-graph-based predictions of repeat lengths for known genetic repeat loci. \n",
    "The ultimate goal is to clean, compile, and process data for many different loci into a summary table, and to \n",
    "provide visualizations pertinent to the functional relevance of this data (i.e. number of samples containing \n",
    "repeat numbers above the pathogenic threshold for each gene).  \n",
    "\n",
    "More information on ExpansionHunter can be found [here](https://academic.oup.com/bioinformatics/article/35/22/4754/5499079). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write license (from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile LICENSE\n",
    "\n",
    "Copyright (c) 2018 The Python Packaging Authority\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of file paths, consisting of all files in the directory containing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile EHT_RDK/input_files.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def create_input_list(directory_name):\n",
    "    file_list = []\n",
    "\n",
    "    # Check to make sure that only '.txt' files are being appended to list\n",
    "    for filename in os.listdir(directory_name):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_list.append(filename)\n",
    "        else:\n",
    "            print('Found non .txt file in directory: ' + filename)\n",
    "            \n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_files import create_input_list\n",
    "\n",
    "# Pass directory containing raw ExpansionHunter - Targeted data\n",
    "files_to_import = create_input_list('/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(files_to_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change into directory containing raw data\n",
    "\n",
    "directory_name = '/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted'\n",
    "os.chdir(directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import first file in file_list \n",
    "test_df = pd.read_csv(file_list[0], sep='\\t')\n",
    "\n",
    "# Examine columns\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'min' and 'max' columns for minimum and maximum allele repeat values respectively\n",
    "test_df['min'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].min(axis=1)\n",
    "test_df['max'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].max(axis=1)\n",
    "\n",
    "# Select only desired columns\n",
    "test_df = test_df[['SampleID','chr','pos','min','max']]\n",
    "\n",
    "print(test_df.columns)\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*EDA suggests that when importing dataframes, need to apply the following:*\n",
    "- evaluate data to create 'min' and 'max' columns\n",
    "- rename 'max' column with gene name\n",
    "- select only desired columns: 'SampleID','chr','pos','max'\n",
    "\n",
    "*EDA did not show any null entries for this df, but need to import with default null value in case all genes were not evaluated for all samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all files from list of filepaths created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a input_files.py\n",
    "\n",
    "def create_dataframe_list(file_list, dir_name):\n",
    "    \"\"\"This function creates a list of dataframes from the passed input list containing filenames. The \n",
    "    'SampleID','chr',and 'pos' columns are retained from the original dataframe, and a new column is created\n",
    "    for the maximum repeats on either allele (column heading is the gene name).\"\"\" \n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for filename in file_list:\n",
    "    \n",
    "        # Get gene name, avoid filenames without expected suffix/prefix\n",
    "        if filename.startswith(\"ExpansionHunterTargeted.ftd\"):\n",
    "            gene = filename.replace(\"ExpansionHunterTargeted.ftd.\",\"\", 1)\n",
    "            if gene.endswith(\".txt\"):\n",
    "                gene = gene.replace(\".txt\",\"\",1)\n",
    "            else:\n",
    "                print(\"filename does not contain suffix\")\n",
    "        else:\n",
    "            print(\"filename does not contain prefix\")\n",
    "    \n",
    "        # Import and format df\n",
    "        df_temp = pd.read_csv(os.path.join(dir_name, filename), sep='\\t')\n",
    "        df_temp.rename(columns={ df_temp.columns[6]: \"allele1\" }, inplace = True)\n",
    "        df_temp.rename(columns={ df_temp.columns[7]: \"allele2\" }, inplace = True)\n",
    "        df_temp['min'] = df_temp[['allele1','allele2']].min(axis=1)\n",
    "        df_temp[gene] = df_temp[['allele1','allele2']].max(axis=1)\n",
    "        df_temp = df_temp[['SampleID','chr','pos',gene]]\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "    return(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK/EHT_RDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_files import create_input_list, create_dataframe_list\n",
    "\n",
    "# Pass list of filenames created earlier, to create list of cleaned dataframes\n",
    "df_list = create_dataframe_list(files_to_import, '/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_list[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of gene info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile process_gene_dfs.py\n",
    "\n",
    "def create_gene_dict(df_list):\n",
    "    \n",
    "    \"\"\"This function creates a dictionary with keys as genes, subdictionaries as key:value pairs for \"chr\", \n",
    "    \"pos\". It uses a list of dataframes passed in as an input parameter..\"\"\" \n",
    "    \n",
    "    gene_dict = {}\n",
    "\n",
    "    for df in df_list:\n",
    "        # Get gene name\n",
    "        gene = df.columns[3]\n",
    "\n",
    "        # Get chromosome\n",
    "        chr_num = df.iloc[0,1]\n",
    "        chr_num = chr_num.replace(\"chr\",\"\",1) # Remove \"chr\" prefix\n",
    "\n",
    "        # Get gene position\n",
    "        pos = df.iloc[0,2]\n",
    "\n",
    "        # Edit dictionary\n",
    "        gene_dict.update( {gene : {\"chr\":chr_num, \"pos\":pos}} )\n",
    "    \n",
    "    return(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_gene_dfs import create_gene_dict\n",
    "\n",
    "gene_dict = create_gene_dict(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge gene-specific dataframes into master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a process_gene_dfs.py\n",
    "\n",
    "def merge_dfs(old_df_list):\n",
    "    \"\"\"This function merges the list of dataframes passed in as an input parameter, by first re-indexing the \n",
    "    dataframes by SampleID, and then merging based on SampleID\"\"\" \n",
    "    \n",
    "    # Change sampleID to index in dfs\n",
    "    df_reindex_list = []\n",
    "\n",
    "    for df in old_df_list:\n",
    "        column_names = list(df.columns)\n",
    "        temp_reindex_df = df.set_index(df['SampleID'])\n",
    "        temp_reindex_df = temp_reindex_df[column_names[1:]]\n",
    "        df_reindex_list.append(temp_reindex_df)\n",
    "\n",
    "    # Create a list of dfs to merge\n",
    "    to_merge = []\n",
    "\n",
    "    for df in df_reindex_list:\n",
    "        column_names = list(df.columns)\n",
    "        temp_df = df[column_names[2]]\n",
    "        to_merge.append(temp_df) \n",
    "\n",
    "    # Merge dfs on sampleID to create master df of all gene max repeat lengths\n",
    "    # Use 'outer' join to keep all samples, including those that do not contain information for all genes\n",
    "    master_df = pd.concat(to_merge, axis = 1, join='outer', sort=False)\n",
    "    \n",
    "    return(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_gene_dfs import merge_dfs\n",
    "\n",
    "master_df = merge_dfs(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis: create summary df of samples with repeats above pathogenic range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile further_analyses.py\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def create_summary_df(genes_of_interest, pathogenic_bounds, gene_dict, master_df, export=False):\n",
    "    \"\"\"This function creates a summary table of the number of pathogenic samples for each of the genes of interest.\n",
    "    It accepts a list of genes of interest, a list of the pathogenic bounds for those genes, the previously\n",
    "    generated gene dictionary, and the master dataframe of all genes and repeat info as input parameters. It\n",
    "    exports the dataframe if the input parameter 'export' is specified as 'True' by the user.\"\"\"\n",
    "\n",
    "    # Add pathogenic range for 10 desired genes to dictionary\n",
    "    for gene in genes_of_interest:\n",
    "        gene_dict[gene].update( {\"pathogenic_bound\":pathogenic_bounds[genes_of_interest.index(gene)]} )\n",
    "\n",
    "    # Count number of samples with repeats greater than or equal to pathogenic_bound\n",
    "    # Append to dictionary\n",
    "    for gene in genes_of_interest:\n",
    "        path_count = len(master_df[master_df[gene] >= gene_dict[gene]['pathogenic_bound']])\n",
    "        gene_dict[gene].update( {\"pathogenic_count\":path_count} )\n",
    "        \n",
    "    # Create new gene dictionary for desired genes only\n",
    "    new_gene_dict = { gene_key: gene_dict[gene_key] for gene_key in genes_of_interest }\n",
    "\n",
    "    # Create dataframe for desired genes using new_gene_dict dictionary\n",
    "    summary_df = pd.DataFrame.from_dict(new_gene_dict, orient='index')\n",
    "    summary_df.columns = ['Chromosome','Position','Pathogenic Bound','Number of Pathogenic Samples']\n",
    "    summary_df.index.name = 'Gene'\n",
    "    \n",
    "    # Export summary dataframe\n",
    "    if export==True:\n",
    "        summary_df.to_csv('Pathoenic_Repeat_Data_Summary', index=True)\n",
    "        \n",
    "    return(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from further_analyses import create_summary_df\n",
    "\n",
    "gene_list = ['AR','ATN1','ATXN1','ATXN3','C9ORF72','DMPK','FMR1','FXN.GAA','HTT.CAG','PHOX2B']\n",
    "bounds_list = [37, 48, 39, 52, 30, 50, 200, 66, 40, 25]\n",
    "\n",
    "summary_df = create_summary_df(gene_list, bounds_list, gene_dict, master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further analysis: create plot of number of pathogenic samples for each gene of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a further_analyses.py\n",
    "\n",
    "def plot_pathogenic(summary_df, export=False):\n",
    "    \n",
    "    \"\"\"This function plots the summary pathogenic repeat counts using the summary_df input parameter\"\"\"\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Plot pathogenic samples for each gene of interest\n",
    "    summary_df['Number of Pathogenic Samples'].plot(kind='bar')\n",
    "    plt.minorticks_on()\n",
    "    plt.title('Summary of Pathogenic Repeat Data')\n",
    "    plt.xlabel('Genes')\n",
    "    plt.ylabel('Number of Pathogenic Samples')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    # Save plot to file \n",
    "    if export==True:\n",
    "        plt.savefig('Pathogenic_Repeat_Data_Summary_Plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from further_analyses import plot_pathogenic\n",
    "\n",
    "plot_pathogenic(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test_input.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_input.py\n",
    "\n",
    "from EHT_RDK.input_files import *\n",
    "\n",
    "def test_input_list():\n",
    "    directory_name = \"/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/Input_test\"\n",
    "    obs = create_input_list(directory_name)\n",
    "    exp = []\n",
    "    assert obs == exp\n",
    "    \n",
    "def test_df_list():\n",
    "    dir_name = \"/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/create_df_test\"\n",
    "    file_list = ['AFF2.txt']\n",
    "    obs = create_dataframe_list(file_list, dir_name)\n",
    "    exp = NotImplemented\n",
    "    assert obs == exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK\n",
      "Installing collected packages: EHT-RDK\n",
      "  Running setup.py develop for EHT-RDK\n",
      "Successfully installed EHT-RDK\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.7.1, pytest-4.0.2, py-1.7.0, pluggy-0.8.0\n",
      "rootdir: /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK, inifile:\n",
      "plugins: remotedata-0.3.1, openfiles-0.3.1, doctestplus-0.2.0, arraydiff-0.3\n",
      "collected 2 items                                                              \u001b[0m\u001b[1m\n",
      "\n",
      "tests/test_input.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[36m                                                   [100%]\u001b[0m\n",
      "\n",
      "\u001b[33m=============================== warnings summary ===============================\u001b[0m\n",
      "/Users/dewanr2/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/inference.py:6\n",
      "  /Users/dewanr2/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/inference.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "    from collections import Iterable\n",
      "\n",
      "/Users/dewanr2/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py:3\n",
      "  /Users/dewanr2/anaconda3/lib/python3.7/site-packages/pandas/core/tools/datetimes.py:3: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "    from collections import MutableMapping\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n",
      "\u001b[33m\u001b[1m===================== 2 passed, 2 warnings in 0.54 seconds =====================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest ./tests/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
