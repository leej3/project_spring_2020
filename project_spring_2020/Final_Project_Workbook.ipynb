{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Workbook\n",
    "### BIOF 309 Spring 2020 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ramita Karra <br>\n",
    "**Last edited:** 04-23-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and set up package files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new a directory and directory structure for the package (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing initialize.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile initialize.py\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "def create_package_dir(package_name='BIOF309_RDK'):\n",
    "    start_dir = Path.cwd()\n",
    "    print(f\"Starting in {start_dir}\")\n",
    "\n",
    "    if start_dir.name == package_name:\n",
    "        os.chdir(start_dir.parent)\n",
    "        package_dir = start_dir\n",
    "    else:\n",
    "        package_dir = start_dir / package_name\n",
    "    \n",
    "    if package_dir.exists():\n",
    "        print(\"Removing old directory...\")\n",
    "        shutil.rmtree(package_dir)\n",
    "\n",
    "    print(f\"Creating {package_dir}...\")\n",
    "    package_dir.mkdir()\n",
    "    print(f\"The current working directory is now {package_dir}\")\n",
    "    os.chdir(package_dir)\n",
    "    \n",
    "def create_package_str(package_name='EHT_RDK'):\n",
    "    Path('tests').mkdir()\n",
    "    python_dir = Path(package_name)\n",
    "    python_dir.mkdir()\n",
    "    (python_dir / '__init__.py').touch()\n",
    "    Path('setup.py').touch()\n",
    "    Path('LICENSE').touch()\n",
    "    Path('README.md').touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting in /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020\n",
      "Creating /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK...\n",
      "The current working directory is now /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK\n"
     ]
    }
   ],
   "source": [
    "from initialize import create_package_dir, create_package_str\n",
    "\n",
    "create_package_dir('BIOF309_RDK')\n",
    "create_package_str('EHT_RDK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metadata and installation details (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"EHT_RDK\", \n",
    "    version=\"0.0.1\",\n",
    "    author=\"Ramita D. Karra\",\n",
    "    author_email=\"ramita.karra@nih.gov\",\n",
    "    description=\"A package for processing Expansion Hunter Targeted (EHT) repeat data\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/pypa/packaging_demo\",\n",
    "    packages=setuptools.find_packages(),\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting README.md\n"
     ]
    }
   ],
   "source": [
    "%%writefile README.md\n",
    "\n",
    "# EHT_RDK\n",
    "## Package Description\n",
    "<br>\n",
    "This aim of this package is to process raw tab-delimited output returned from the ExpansionHunter-Targeted \n",
    "software tool, used for making sequence-graph-based predictions of repeat lengths for known genetic repeat loci. \n",
    "The ultimate goal is to clean, compile, and process data for many different loci into a summary table, and to \n",
    "provide visualizations pertinent to the functional relevance of this data (i.e. number of samples containing \n",
    "repeat numbers above the pathogenic threshold for each gene).  \n",
    "\n",
    "More information on ExpansionHunter can be found [here](https://academic.oup.com/bioinformatics/article/35/22/4754/5499079). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write license (from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting LICENSE\n"
     ]
    }
   ],
   "source": [
    "%%writefile LICENSE\n",
    "\n",
    "Copyright (c) 2018 The Python Packaging Authority\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of file paths, consisting of all files in the directory containing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting input_files.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile input_files.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def create_input_list(directory_name):\n",
    "    file_list = []\n",
    "\n",
    "    # Check to make sure that only '.txt' files are being appended to list\n",
    "    for filename in os.listdir(directory_name):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_list.append(filename)\n",
    "        else:\n",
    "            print('Found non .txt file in directory: ' + filename)\n",
    "            \n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_files import create_input_list\n",
    "\n",
    "# Pass directory containing raw ExpansionHunter - Targeted data\n",
    "files_to_import = create_input_list('/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ExpansionHunterTargeted.ftd.ATXN7.GCC.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN7.GCA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.TCF4.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CACNA1A.txt',\n",
       " 'ExpansionHunterTargeted.ftd.HTT.CAG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.PPP2R2B.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CNBP.CAGG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.JPH3.txt',\n",
       " 'ExpansionHunterTargeted.ftd.FXN.GAA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CBL.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CSTB.txt',\n",
       " 'ExpansionHunterTargeted.ftd.DIP2B.txt',\n",
       " 'ExpansionHunterTargeted.ftd.NOP56.CGCCTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CNBP.CAGA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.AR.txt',\n",
       " 'ExpansionHunterTargeted.ftd.TBP.txt',\n",
       " 'ExpansionHunterTargeted.ftd.HTT.CCG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.DMPK.txt',\n",
       " 'ExpansionHunterTargeted.ftd.FMR1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN8OS.CTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.NOP56.GGCCTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN8OS.CTA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN10.txt',\n",
       " 'ExpansionHunterTargeted.ftd.C9ORF72.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN3.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN2.txt',\n",
       " 'ExpansionHunterTargeted.ftd.AFF2.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATN1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.PHOX2B.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(files_to_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change into directory containing raw data\n",
    "\n",
    "directory_name = '/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted'\n",
    "os.chdir(directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Cohort', 'SampleID', 'chr', 'pos', 'INFO',\n",
      "       'GT:SO:REPCN:REPCI:ADSP:ADFL:ADIR:LC', 'REPCN:ATXN7_GCC_allele1',\n",
      "       'REPCN:ATXN7_GCC_allele2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import first file in file_list \n",
    "test_df = pd.read_csv(file_list[0], sep='\\t')\n",
    "\n",
    "# Examine columns\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SampleID', 'chr', 'pos', 'min', 'max'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1938 entries, 0 to 1937\n",
      "Data columns (total 5 columns):\n",
      "SampleID    1938 non-null object\n",
      "chr         1938 non-null object\n",
      "pos         1938 non-null int64\n",
      "min         1938 non-null int64\n",
      "max         1938 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 75.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create 'min' and 'max' columns for minimum and maximum allele repeat values respectively\n",
    "test_df['min'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].min(axis=1)\n",
    "test_df['max'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].max(axis=1)\n",
    "\n",
    "# Select only desired columns\n",
    "test_df = test_df[['SampleID','chr','pos','min','max']]\n",
    "\n",
    "print(test_df.columns)\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*EDA suggests that when importing dataframes, need to apply the following:*\n",
    "- evaluate data to create 'min' and 'max' columns\n",
    "- rename 'max' column with gene name\n",
    "- select only desired columns: 'SampleID','chr','pos','max'\n",
    "\n",
    "*EDA did not show any null entries for this df, but need to import with default null value in case all genes were not evaluated for all samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all files from list of filepaths created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that current directory contains raw data\n",
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of dataframes with columns: 'SampleID','chr','pos','min','max'\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for filename in file_list:\n",
    "    \n",
    "    # Get gene name\n",
    "    if filename.startswith(\"ExpansionHunterTargeted.ftd\"):\n",
    "        gene = filename.replace(\"ExpansionHunterTargeted.ftd.\",\"\", 1)\n",
    "        if gene.endswith(\".txt\"):\n",
    "            gene = gene.replace(\".txt\",\"\",1)\n",
    "        else:\n",
    "            print(\"filename does not contain suffix\")\n",
    "    else:\n",
    "        print(\"filename does not contain prefix\")\n",
    "    \n",
    "    # Import and format df\n",
    "    df_temp = pd.read_csv(filename, sep='\\t')\n",
    "    df_temp.rename(columns={ df_temp.columns[6]: \"allele1\" }, inplace = True)\n",
    "    df_temp.rename(columns={ df_temp.columns[7]: \"allele2\" }, inplace = True)\n",
    "    df_temp['min'] = df_temp[['allele1','allele2']].min(axis=1)\n",
    "    df_temp[gene] = df_temp[['allele1','allele2']].max(axis=1)\n",
    "    df_temp = df_temp[['SampleID','chr','pos',gene]]\n",
    "    df_list.append(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>ATXN7.GCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RES04914</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RES08323</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RES04107</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RES05106</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RES04513</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SampleID   chr       pos  ATXN7.GCC\n",
       "0  RES04914  chr3  63912714         16\n",
       "1  RES08323  chr3  63912714         15\n",
       "2  RES04107  chr3  63912714         14\n",
       "3  RES05106  chr3  63912714         13\n",
       "4  RES04513  chr3  63912714         13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_list[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of gene info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with keys as genes, subdictionaries as key:value pairs for \"chr\", \"pos\"\n",
    "\n",
    "gene_dict = {}\n",
    "\n",
    "for df in df_list:\n",
    "    # Get gene name\n",
    "    gene = df.columns[3]\n",
    "    \n",
    "    # Get chromosome\n",
    "    chr_num = df.iloc[0,1]\n",
    "    chr_num = chr_num.replace(\"chr\",\"\",1) # Remove \"chr\" prefix\n",
    "    \n",
    "    # Get gene position\n",
    "    pos = df.iloc[0,2]\n",
    "    \n",
    "    # Edit dictionary\n",
    "    gene_dict.update( {gene : {\"chr\":chr_num, \"pos\":pos}} )a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chr': '9', 'pos': 27573528}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(gene_dict['C9ORF72'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge gene-specific dataframes into master dataframe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
