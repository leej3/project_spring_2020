{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Workbook\n",
    "### BIOF 309 Spring 2020 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author:** Ramita Karra <br>\n",
    "**Last edited:** 04-23-2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and set up package files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create new a directory and directory structure for the package (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile initialize.py\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil \n",
    "\n",
    "def create_package_dir(package_name='BIOF309_RDK'):\n",
    "    \"\"\" This function creates a new directory within the current directory using the passed input string \n",
    "    package_name. If a directory with the same name as package_name already exists, it deletes the old \n",
    "    directory.\"\"\"\n",
    "    \n",
    "    start_dir = Path.cwd()\n",
    "    print(f\"Starting in {start_dir}\")\n",
    "\n",
    "    if start_dir.name == package_name:\n",
    "        os.chdir(start_dir.parent)\n",
    "        package_dir = start_dir\n",
    "    else:\n",
    "        package_dir = start_dir / package_name\n",
    "    \n",
    "    if package_dir.exists():\n",
    "        print(\"Removing old directory...\")\n",
    "        shutil.rmtree(package_dir)\n",
    "\n",
    "    print(f\"Creating {package_dir}...\")\n",
    "    package_dir.mkdir()\n",
    "    print(f\"The current working directory is now {package_dir}\")\n",
    "    os.chdir(package_dir)\n",
    "    \n",
    "def create_package_str(package_name='EHT_RDK'):\n",
    "    \"\"\" This function creates a new package structure within the current directory. It creates a new directory\n",
    "    to house code, with the passed input string package_name, as well as blank files for 'init.py' within the \n",
    "    new directory, setup.py, License and Readme files.\"\"\"\n",
    "    \n",
    "    Path('tests').mkdir()\n",
    "    python_dir = Path(package_name)\n",
    "    python_dir.mkdir()\n",
    "    (python_dir / '__init__.py').touch()\n",
    "    Path('setup.py').touch()\n",
    "    Path('LICENSE').touch()\n",
    "    Path('README.md').touch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from initialize import create_package_dir, create_package_str\n",
    "\n",
    "create_package_dir('BIOF309_RDK')\n",
    "create_package_str('EHT_RDK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metadata and installation details (slightly modified code from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile setup.py\n",
    "\n",
    "# Metadata and installation details for the EHT_RDK package\n",
    "\n",
    "import setuptools\n",
    "\n",
    "with open(\"README.md\", \"r\") as fh:\n",
    "    long_description = fh.read()\n",
    "\n",
    "setuptools.setup(\n",
    "    name=\"EHT_RDK\", \n",
    "    version=\"0.0.1\",\n",
    "    author=\"Ramita D. Karra\",\n",
    "    author_email=\"ramita.karra@nih.gov\",\n",
    "    description=\"A package for processing Expansion Hunter Targeted (EHT) repeat data\",\n",
    "    long_description=long_description,\n",
    "    long_description_content_type=\"text/markdown\",\n",
    "    url=\"https://github.com/pypa/packaging_demo\",\n",
    "    packages=setuptools.find_packages(),\n",
    "    classifiers=[\n",
    "        \"Programming Language :: Python :: 3\",\n",
    "        \"License :: OSI Approved :: MIT License\",\n",
    "        \"Operating System :: OS Independent\",\n",
    "    ],\n",
    "    python_requires='>=3.6',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile README.md\n",
    "\n",
    "# EHT_RDK\n",
    "## Package Description\n",
    "<br>\n",
    "This aim of this package is to process raw tab-delimited output returned from the ExpansionHunter-Targeted \n",
    "software tool, used for making sequence-graph-based predictions of repeat lengths for known genetic repeat loci. \n",
    "The ultimate goal is to clean, compile, and process data for many different loci into a summary table, and to \n",
    "provide visualizations pertinent to the functional relevance of this data (i.e. number of samples containing \n",
    "repeat numbers above the pathogenic threshold for each gene).  \n",
    "\n",
    "More information on ExpansionHunter can be found [here](https://academic.oup.com/bioinformatics/article/35/22/4754/5499079). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write license (from class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile LICENSE\n",
    "\n",
    "Copyright (c) 2018 The Python Packaging Authority\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a list of file paths, consisting of all files in the directory containing raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile EHT_RDK/input_files.py\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "def create_input_list(directory_name):\n",
    "    file_list = []\n",
    "\n",
    "    # Check to make sure that only '.txt' files are being appended to list\n",
    "    for filename in os.listdir(directory_name):\n",
    "        if filename.endswith('.txt'):\n",
    "            file_list.append(filename)\n",
    "        else:\n",
    "            print('Found non .txt file in directory: ' + filename)\n",
    "            \n",
    "    return(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_files import create_input_list\n",
    "\n",
    "# Pass directory containing raw ExpansionHunter - Targeted data\n",
    "files_to_import = create_input_list('/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ExpansionHunterTargeted.ftd.ATXN7.GCC.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN7.GCA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.TCF4.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CACNA1A.txt',\n",
       " 'ExpansionHunterTargeted.ftd.HTT.CAG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.PPP2R2B.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CNBP.CAGG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.JPH3.txt',\n",
       " 'ExpansionHunterTargeted.ftd.FXN.GAA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CBL.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CSTB.txt',\n",
       " 'ExpansionHunterTargeted.ftd.DIP2B.txt',\n",
       " 'ExpansionHunterTargeted.ftd.NOP56.CGCCTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.CNBP.CAGA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.AR.txt',\n",
       " 'ExpansionHunterTargeted.ftd.TBP.txt',\n",
       " 'ExpansionHunterTargeted.ftd.HTT.CCG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.DMPK.txt',\n",
       " 'ExpansionHunterTargeted.ftd.FMR1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN8OS.CTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.NOP56.GGCCTG.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN8OS.CTA.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN10.txt',\n",
       " 'ExpansionHunterTargeted.ftd.C9ORF72.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN3.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN2.txt',\n",
       " 'ExpansionHunterTargeted.ftd.AFF2.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATXN1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.ATN1.txt',\n",
       " 'ExpansionHunterTargeted.ftd.PHOX2B.txt']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(files_to_import)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change into directory containing raw data\n",
    "\n",
    "directory_name = '/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted'\n",
    "os.chdir(directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import first file in file_list \n",
    "test_df = pd.read_csv(file_list[0], sep='\\t')\n",
    "\n",
    "# Examine columns\n",
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'min' and 'max' columns for minimum and maximum allele repeat values respectively\n",
    "test_df['min'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].min(axis=1)\n",
    "test_df['max'] = test_df[['REPCN:ATXN7_GCC_allele1','REPCN:ATXN7_GCC_allele2']].max(axis=1)\n",
    "\n",
    "# Select only desired columns\n",
    "test_df = test_df[['SampleID','chr','pos','min','max']]\n",
    "\n",
    "print(test_df.columns)\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*EDA suggests that when importing dataframes, need to apply the following:*\n",
    "- evaluate data to create 'min' and 'max' columns\n",
    "- rename 'max' column with gene name\n",
    "- select only desired columns: 'SampleID','chr','pos','max'\n",
    "\n",
    "*EDA did not show any null entries for this df, but need to import with default null value in case all genes were not evaluated for all samples*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all files from list of filepaths created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to input_files.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a input_files.py\n",
    "\n",
    "def create_dataframe_list(file_list, dir_name):\n",
    "    \"\"\"This function creates a list of dataframes from the passed input list containing filenames. The \n",
    "    'SampleID','chr',and 'pos' columns are retained from the original dataframe, and a new column is created\n",
    "    for the maximum repeats on either allele (column heading is the gene name).\"\"\" \n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    for filename in file_list:\n",
    "    \n",
    "        # Get gene name\n",
    "        if filename.startswith(\"ExpansionHunterTargeted.ftd\"):\n",
    "            gene = filename.replace(\"ExpansionHunterTargeted.ftd.\",\"\", 1)\n",
    "            if gene.endswith(\".txt\"):\n",
    "                gene = gene.replace(\".txt\",\"\",1)\n",
    "            else:\n",
    "                print(\"filename does not contain suffix\")\n",
    "        else:\n",
    "            print(\"filename does not contain prefix\")\n",
    "    \n",
    "        # Import and format df\n",
    "        df_temp = pd.read_csv(os.path.join(dir_name, filename), sep='\\t')\n",
    "        df_temp.rename(columns={ df_temp.columns[6]: \"allele1\" }, inplace = True)\n",
    "        df_temp.rename(columns={ df_temp.columns[7]: \"allele2\" }, inplace = True)\n",
    "        df_temp['min'] = df_temp[['allele1','allele2']].min(axis=1)\n",
    "        df_temp[gene] = df_temp[['allele1','allele2']].max(axis=1)\n",
    "        df_temp = df_temp[['SampleID','chr','pos',gene]]\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "    return(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK/EHT_RDK\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK/EHT_RDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_files import create_input_list, create_dataframe_list\n",
    "\n",
    "# Pass list of filenames created earlier, to create list of cleaned dataframes\n",
    "df_list = create_dataframe_list(files_to_import, '/Users/dewanr2/Documents/Ramitas_Docs/NIH_Classes/BIOF309/ExpansionHunterTargeted/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>ATXN7.GCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RES04914</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RES08323</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RES04107</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RES05106</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RES04513</td>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SampleID   chr       pos  ATXN7.GCC\n",
       "0  RES04914  chr3  63912714         16\n",
       "1  RES08323  chr3  63912714         15\n",
       "2  RES04107  chr3  63912714         14\n",
       "3  RES05106  chr3  63912714         13\n",
       "4  RES04513  chr3  63912714         13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_list[0].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dictionary of gene info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dewanr2/Documents/GitHub/project_spring_2020/project_spring_2020/BIOF309_RDK/EHT_RDK'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting process_gene_dfs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process_gene_dfs.py\n",
    "\n",
    "def create_gene_dict(df_list):\n",
    "    \n",
    "    \"\"\"This function creates a dictionary with keys as genes, subdictionaries as key:value pairs for \"chr\", \n",
    "    \"pos\". It uses a list of dataframes passed in as an input parameter..\"\"\" \n",
    "    \n",
    "    gene_dict = {}\n",
    "\n",
    "    for df in df_list:\n",
    "        # Get gene name\n",
    "        gene = df.columns[3]\n",
    "\n",
    "        # Get chromosome\n",
    "        chr_num = df.iloc[0,1]\n",
    "        chr_num = chr_num.replace(\"chr\",\"\",1) # Remove \"chr\" prefix\n",
    "\n",
    "        # Get gene position\n",
    "        pos = df.iloc[0,2]\n",
    "\n",
    "        # Edit dictionary\n",
    "        gene_dict.update( {gene : {\"chr\":chr_num, \"pos\":pos}} )\n",
    "    \n",
    "    return(gene_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_gene_dfs import create_gene_dict\n",
    "\n",
    "gene_dict = create_gene_dict(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chr': '9', 'pos': 27573528}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(gene_dict['C9ORF72'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge gene-specific dataframes into master dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>ATXN7.GCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SampleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RES04914</th>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RES08323</th>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RES04107</th>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RES05106</th>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RES04513</th>\n",
       "      <td>chr3</td>\n",
       "      <td>63912714</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chr       pos  ATXN7.GCC\n",
       "SampleID                           \n",
       "RES04914  chr3  63912714         16\n",
       "RES08323  chr3  63912714         15\n",
       "RES04107  chr3  63912714         14\n",
       "RES05106  chr3  63912714         13\n",
       "RES04513  chr3  63912714         13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change sampleID to index in dfs\n",
    "\n",
    "df_reindex_list = []\n",
    "\n",
    "for df in df_list:\n",
    "    column_names = list(df.columns)\n",
    "    temp_reindex_df = df.set_index(df['SampleID'])\n",
    "    temp_reindex_df = temp_reindex_df[column_names[1:]]\n",
    "    df_reindex_list.append(temp_reindex_df)\n",
    "    \n",
    "display(df_reindex_list[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dfs on sampleID to create master df of all gene max repeat lengths\n",
    "\n",
    "## Further analysis\n",
    "# Add pathogenic range for desired genes to dictionary\n",
    "\n",
    "# Create summary df of number of samples with repeats above pathogenic range\n",
    "\n",
    "# Create histogram for each gene of interest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
